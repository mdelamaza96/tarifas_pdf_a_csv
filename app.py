import streamlit as st
import requests
from bs4 import BeautifulSoup
import os
import PyPDF2
import pandas as pd
from datetime import datetime
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(page_title="Tarifas SAESA (Autom√°tico)", layout="wide")
st.title("üìä Dashboard Tarifas SAESA con Scraping + Backup URL")

# Inputs
mes = st.selectbox("Mes", ["enero","febrero","marzo","abril","mayo","junio",
                            "julio","agosto","septiembre","octubre","noviembre","diciembre"])
anio = st.number_input("A√±o", min_value=2020, max_value=datetime.now().year, value=datetime.now().year)

comunas = [
    "Osorno", "Puerto Montt", "Ancud", "Castro", "Quell√≥n", "Chonchi", "Dalcahue", "Puqueld√≥n",
    "Quemchi", "Curaco de V√©lez", "Queil√©n", "Frutillar", "Llanquihue", "Calbuco", "Maull√≠n",
    "Hualaihu√©", "Fresia", "Los Muermos", "Purranque", "R√≠o Negro", "San Pablo",
    "San Juan de la Costa", "La Uni√≥n", "R√≠o Bueno", "Paillaco", "Futrono", "Lago Ranco",
    "Valdivia", "Mariquina", "Corral", "M√°fil", "Lanco", "Panguipulli", "Los Lagos",
    "Chait√©n", "Palena", "Futaleuf√∫", "Cocham√≥", "Hornopir√©n"
]
comuna = st.selectbox("Comuna", comunas)

tarifas = ["BT1","BT2","BT3","BT4","AT","MT"]
tipo_tarifa = st.selectbox("Tarifa", tarifas)

BACKUP_URL = "https://www.saesa.cl/adjuntos/Pliego_tarifario_Suministro_Regulado.pdf"

def obtener_enlace_pliego():
    url = "https://www.gruposaesa.cl/saesa/tarifas-vigentes"
    try:
        res = requests.get(url, verify=False, timeout=10)
        if res.status_code != 200:
            return None
        soup = BeautifulSoup(res.text, "html.parser")
        for a in soup.find_all("a", href=True):
            href = a.get("href")
            txt = (a.text or "").lower()
            if href.lower().endswith(".pdf") and "regulado" in txt:
                return href
    except:
        return None
    return None

def descargar_pdf(url):
    try:
        res = requests.get(url, verify=False)
        ctype = res.headers.get("Content-Type", "")
        if res.status_code == 200 and "pdf" in ctype.lower():
            fname = "pliego.pdf"
            with open(fname, "wb") as f:
                f.write(res.content)
            return fname
    except:
        pass
    return None

def extraer_cargos(pdf_path):
    data = []
    with open(pdf_path, "rb") as f:
        reader = PyPDF2.PdfReader(f)
        for p in reader.pages:
            txt = p.extract_text() or ""
            if comuna.lower() in txt.lower() and tipo_tarifa.upper() in txt.upper():
                for line in txt.split("\n"):
                    if any(x in line for x in ["Cargo", "$", "%", "kWh"]):
                        data.append({"Detalle": line.strip()})
    return data

if st.button("Ejecutar b√∫squeda y descarga"):
    st.info("üîç Buscando pliego tarifario regulado...")
    link = obtener_enlace_pliego()

    if not link:
        st.warning("‚ö†Ô∏è No se encontr√≥ el PDF autom√°ticamente. Usando URL de respaldo.")
        link = BACKUP_URL

    st.write("üìé Enlace utilizado:", link)
    fname = descargar_pdf(link)
    if not fname:
        st.error("‚ùå No se pudo descargar el archivo PDF.")
    else:
        st.success("‚úÖ PDF descargado correctamente")
        cargos = extraer_cargos(fname)
        os.remove(fname)
        if cargos:
            st.dataframe(pd.DataFrame(cargos))
        else:
            st.warning("‚ö†Ô∏è No se encontraron cargos para los criterios seleccionados.")
